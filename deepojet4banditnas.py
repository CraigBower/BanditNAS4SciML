# -*- coding: utf-8 -*-
"""DeepOJet4BanditNAS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MzY5PmPUweeKFNTm_5M5vtuqucj0tUh_
"""

import glob
import pandas as pd
import numpy as np
import h5py
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
from scipy.ndimage import label, find_objects
import datetime
from scipy.ndimage import zoom
from tensorflow import keras
import tensorflow as tf
from tensorflow.keras import layers, Model
import os
from PIL import Image
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from keras.optimizers import Adam, SGD
from keras.preprocessing.image import *
from keras.utils import plot_model
from tensorflow.keras.models import Sequential
from tqdm.notebook import tqdm
from scipy.signal import find_peaks
from scipy.spatial import cKDTree
from scipy.optimize import minimize
from google.colab import drive, files
drive.mount('/content/drive', force_remount=True)

import warnings
warnings.filterwarnings("ignore")

# Display the GIF in notebook (if using Jupyter)
from IPython.display import display, Image as IPImage

def getParticlesInSlice(pos, width, height, Xpixels, Ypixels, unique=True):
  xa, ya, za = pos.T
  Xmin = -width/2
  Xmax = width/2
  Ymin = -height/2
  Ymax = height/2
  dx = (Xmax - Xmin) / float(Xpixels)
  dy = (Ymax - Ymin) / float(Ypixels)
  x = np.linspace(Xmin + dx/2, Xmax - dx/2, Xpixels)
  y = np.linspace(Ymin + dy/2, Ymax - dy/2, Ypixels)
  grid_particles = np.dstack((xa.ravel(), ya.ravel(), za.ravel()))[0]
  gas_tree = cKDTree(grid_particles)
  X, Y, Z = np.meshgrid(x, y, 0)
  grid_points = np.dstack((X.ravel(), Y.ravel(), Z.ravel()))[0]
  rp, loc = gas_tree.query(list(grid_points), k=1)
  return np.unique(loc) if unique == True else loc

def generateSlice(quant, pos, width, height, Xpixels, Ypixels):
  loc = getParticlesInSlice(pos, width, height, Xpixels, Ypixels, False)
  image = np.reshape(quant[loc], [Xpixels, Ypixels])
  return image

files = sorted(glob.glob('drive/MyDrive/snap*'))
def getData(files, snapshot, res, VARIABLE):

  UnitMass = 1.989e43
  UnitLength = 3.086e21
  UnitVel = 1.e5
  UnitTime = UnitLength / UnitVel
  UnitDensity = UnitMass / UnitLength**3
  UnitEnergy = UnitMass * UnitVel**2
  UnitPressure = UnitEnergy / UnitLength**3
  Grav = 6.6742e-8
  CLIGHT = 3.e10
  PROTONMASS = 1.6726e-24
  BOLTZMANN = 1.38065e-16
  THOMPSON = 6.65e-25
  PI = np.pi
  HYDROGEN_MASSFRAC = 0.76
  GAMMA_MINUS1 = 5/3 - 1
  KPC = 3.086e21

  dim = 500
  hdim = dim/2
  boxsize = 100000
  hbox = boxsize/2
  cen = np.array([hbox, hbox, hbox])

  file = files[snapshot]
  hf = h5py.File(file, 'r')['PartType0']

  posg = hf['Coordinates'][:] - cen
  if VARIABLE == 'Density':
    rhog = hf[VARIABLE][:]
    rhog *= UnitDensity
  elif VARIABLE == 'Pressure':
    rhog =  np.multiply(hf['Density'][:], hf['InternalEnergy'][:]) * GAMMA_MINUS1
    rhog *= UnitPressure
  elif VARIABLE == 'InternalEnergy':
    rhog = hf[VARIABLE][:]
    #rhog *= UnitEnergy
  elif VARIABLE == 'Vx':
    rhog = hf['Velocities'][()][:, 0]
  elif VARIABLE == 'Vy':
    rhog = hf['Velocities'][()][:, 1]
  elif VARIABLE == 'Vz':
    rhog = hf['Velocities'][()][:, 1]

  posg *= UnitLength / KPC
  x, y, z = posg.T
  posg1 = np.array([x, z, y]).T
  sliceRho = generateSlice(rhog, posg1, dim, dim, res, res)
  if not VARIABLE == 'Vx' and not VARIABLE == 'Vy' and not VARIABLE == 'Vz':
    data = np.log10(sliceRho)
  else:
    data = sliceRho
  return data

def normalise(data, min_val, max_val):
  data = (data - min_val) / (max_val - min_val)
  return data

def scale_array(arr, scale_factor):
  return zoom(arr, scale_factor, order=3)

g# Create a sequence of n x n numpy images using matplotlib
def create_images(PREDICTIONS, VMAX, VMIN, INFERENCE_TIMES=None, TITLE=None):
    images = []
    for i in range(len(PREDICTIONS)):
        # Create a random n x n image
        #data = np.random.rand(img_size, img_size)
        data = PREDICTIONS[i]

        # Create a figure and axis
        fig, ax = plt.subplots(figsize=(10,10))

        # Display the image using imshow
        #ax.imshow(data, cmap='jet', interpolation='none')
        #ax.axis('off')  # Hide axes

        #plt.figure(figsize=(fdim,fdim))
        im = ax.imshow(data, origin='lower', extent=EXTENT, cmap='jet', vmax=VMAX, vmin=VMIN)

        # Get current ticks for x and y axes
        xticks = ax.get_xticks()
        yticks = ax.get_yticks()

        # Set the ticks and fontsize
        # Provide the current tick labels as the labels argument along with fontsize
        ax.set_xticks(xticks, labels=[str(int(tick)) for tick in xticks], fontsize=15, rotation=90)
        ax.set_yticks(yticks, labels=[str(int(tick)) for tick in yticks], fontsize=15)

        ax.set_ylabel('z (kpc)', fontsize=15)
        ax.set_xlabel('x (kpc)', fontsize=15)
        cb = fig.colorbar(im, fraction=0.0458, pad=0.04)
        cb.set_label(label=f'log(' + r'$\rho$' + ')' + ' (Normalised)', size=15)
        cb.ax.tick_params(labelsize=15)
        if not INFERENCE_TIMES is None:
          inference_time = INFERENCE_TIMES[i]
          ax.set_title(f'{TITLE}\nSnapshot: {i+1}\n' + f'Inference time: {inference_time:.3f}s', fontsize=15)
        else:
          if 'Input' in TITLE:
            ax.set_title(f'{TITLE}\nSnapshot: {i}', fontsize=15)
          else:
            ax.set_title(f'{TITLE}\nSnapshot: {i+1}', fontsize=15)

        # Save the plot to a numpy array
        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')
        image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (3,))

        # Add the image to the list
        images.append(image_from_plot)

        plt.close(fig)  # Close the figure to save memory
    return images

# Save images as a GIF that loops indefinitely
def save_images_as_gif(images, gif_path, duration):
    pil_images = [Image.fromarray(image) for image in images]
    pil_images[0].save(gif_path, save_all=True, append_images=pil_images[1:], duration=duration, loop=0)  # loop=0 for infinite loop

import cv2
import os

# Save images as an MP4 video using OpenCV
def save_images_as_mp4(images, video_path, fps=10):
    height, width, _ = images[0].shape  # Get size from the first image
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4
    out = cv2.VideoWriter(video_path, fourcc, fps, (width, height))

    for img in images:
        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR (OpenCV format)
        out.write(img_bgr)  # Write each image as a frame

    out.release()  # Close the video file

#import matplotlib.pyplot as plt
#import numpy as np
#import os
#from PIL import Image

def save_subplots_as_gif(figures, output_filename='drive/MyDrive/BASE-II_animation.gif', fps=10, **kwargs):
    """
    Convert a sequence of matplotlib figures with subplots into a GIF animation.

    Parameters:
    -----------
    figures : list
        A list of matplotlib figure objects, each containing subplots.
    output_filename : str, optional
        The name of the output GIF file. Default is 'animation.gif'.
    fps : int, optional
        Frames per second in the output GIF. Default is 10.
    **kwargs : dict
        Additional keyword arguments to pass to PIL's save method.

    Returns:
    --------
    None
    """
    # Create a temporary directory to save individual frames
    temp_dir = 'drive/MyDrive/temp_frames'
    os.makedirs(temp_dir, exist_ok=True)

    # Save each figure as a separate image
    filenames = []
    for i, fig in enumerate(figures):
        # Save with tight layout to prevent cropping of subplots
        filename = f'{temp_dir}/frame_{i:03d}.png'
        fig.tight_layout()
        fig.savefig(filename, bbox_inches='tight', dpi=150)
        filenames.append(filename)

    # Use PIL to create GIF from saved images
    frames = [Image.open(filename) for filename in filenames]

    # Save as GIF
    duration_ms = 1000 // fps  # Convert fps to duration in milliseconds
    frames[0].save(
        output_filename,
        save_all=True,
        append_images=frames[1:],
        duration=duration_ms,
        loop=0,
        **kwargs
    )

    # Clean up temporary files
    for filename in filenames:
        os.remove(filename)
    os.rmdir(temp_dir)

    print(f"GIF animation saved as {output_filename}")

def moving_average(data, window_size):
    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')

def cocoon_ellipse(data, threshold_above, threshold_below, mid, plot_id, res, color):

  # Find regions with values greater than the threshold
  regions, num_features = label((data >= threshold_below)&(data <= threshold_above))

  # Iterate over each region and draw an ellipse around it
  for region_slice in find_objects(regions):
    # Calculate the center of the region
    y_center = (region_slice[0].start + region_slice[0].stop - 1) / 2
    x_center = (region_slice[1].start + region_slice[1].stop - 1) / 2

    # Calculate the width and height of the region
    width = region_slice[1].stop - region_slice[1].start
    height = region_slice[0].stop - region_slice[0].start

    # Draw an ellipse around the region
    ellipse = Ellipse(
        ((x_center - res/2 + 0.5)* 500/res, (y_center - res/2 + 0.5)* 500/res),
        width=width * (500 / res),
        height=height * (500 / res),
        edgecolor=color,
        facecolor='none'
        )
    ax[plot_id].add_patch(ellipse)

def build_branch_net(input_dim, output_dim, hidden_units=64, num_layers=4):
    """Branch network to process density input."""
    inputs = layers.Input(shape=(input_dim,))
    x = inputs
    for _ in range(num_layers):
        x = layers.Dense(hidden_units, activation='relu')(x)
    outputs = layers.Dense(output_dim)(x)  # Latent representation
    return Model(inputs, outputs, name="BranchNet")

def build_trunk_net(input_dim, output_dim, hidden_units=64, num_layers=4):
    """Trunk network to process spatial coordinates."""
    inputs = layers.Input(shape=(input_dim,))
    x = inputs
    for _ in range(num_layers):
        x = layers.Dense(hidden_units, activation='relu')(x)
    outputs = layers.Dense(output_dim)(x)  # Latent representation
    return Model(inputs, outputs, name="TrunkNet")

def build_time_net(input_dim, output_dim, hidden_units=64, num_layers=4):
    """Time branch network to process temporal information."""
    inputs = layers.Input(shape=(input_dim,))
    x = inputs
    for _ in range(num_layers):
        x = layers.Dense(hidden_units, activation='relu')(x)
    outputs = layers.Dense(output_dim)(x)  # Latent representation
    return Model(inputs, outputs, name="TimeNet")

def build_implicit_flow_model_v3(branch_input_dim, trunk_input_dim, time_input_dim, latent_dim, train_n, hidden_units=64, num_layers=4):
    """
    Neural Implicit Flow Model with separate time branch and flexible spatial resolution.
    """
    # Branch network processes density (flattened input of (train_n, train_n, 1))
    branch_net = build_branch_net(branch_input_dim, latent_dim, hidden_units, num_layers)

    # Trunk network processes spatial coordinates
    trunk_net = build_trunk_net(trunk_input_dim, latent_dim, hidden_units, num_layers)

    # Time network processes temporal information
    time_net = build_time_net(time_input_dim, latent_dim, hidden_units, num_layers)

    # Inputs to the model
    density_input = layers.Input(shape=(train_n, train_n, 1), name="density_input")  # Shape: (train_n, train_n, 1)
    coord_input = layers.Input(shape=(None, trunk_input_dim), name="coord_input")  # Flexible resolution (None, trunk_input_dim)
    time_input = layers.Input(shape=(time_input_dim,), name="time_input")  # Shape: (time_input_dim,)

    # Flatten density input for branch network
    density_flattened = layers.Flatten()(density_input)  # Shape: (train_n * train_n,)
    branch_output = branch_net(density_flattened)  # Shape: (latent_dim,)

    # Trunk network processes coordinates (flexible resolution)
    trunk_output = layers.TimeDistributed(trunk_net)(coord_input)  # Shape: (None, latent_dim)

    # Time network processes temporal input
    time_output = time_net(time_input)  # Shape: (latent_dim,)

    # Combine all outputs: branch (density), trunk (spatial), and time
    combined_features = layers.Multiply()([trunk_output, branch_output])  # Shape: (None, latent_dim)
    combined_features = layers.Add()([combined_features, time_output])  # Add time contribution

    # Final prediction: reduce along latent dimension and reshape to match output resolution
    output_density = layers.Dense(1)(combined_features)  # Shape: (None, 1)

    # Build the model
    return Model(inputs=[density_input, coord_input, time_input], outputs=output_density, name="ImplicitFlowModelV3")

TRAINING_RESOLUTION = 512  # Training spatial resolution
PATH = f'drive/MyDrive/108Snaps_100Samples_{TRAINING_RESOLUTION}Res/'

# Generate synthetic data
NUM_SAMPLES = 107
X_RES, Y_RES = TRAINING_RESOLUTION, TRAINING_RESOLUTION
NUM_COORDS = X_RES * Y_RES  # Number of spatial points for coord_data
TRUNK_INPUT_DIM = 2
TIME_INPUT_DIM = 1  # Single time step
LATENT_DIM = 64  # Latent dimension of the model

NORMALISED_TRAINING_DATA = np.load(PATH + f'NORMALISED_TRAINING_DATA_res{TRAINING_RESOLUTION}.npy', allow_pickle=True)

density_data = np.array([NORMALISED_TRAINING_DATA[i] for i in range(NUM_SAMPLES)]).reshape(NUM_SAMPLES, TRAINING_RESOLUTION, TRAINING_RESOLUTION, 1)
# Define the training mesh (32x32 points in 2D)
x_train_mesh = np.linspace(0, 1, X_RES)
y_train_mesh = np.linspace(0, 1, Y_RES)
X_train_mesh, Y_train_mesh = np.meshgrid(x_train_mesh, y_train_mesh)  # Shape: (32, 32)
mesh_points_train = np.stack([X_train_mesh.ravel(), Y_train_mesh.ravel()], axis=-1)  # Shape: (1024, 2)
# Trunk inputs are the coordinates (x, y) for each point on the 2D mesh
coord_data = np.tile(mesh_points_train, (NUM_SAMPLES, 1, 1))  # Shape: (100, 1024, 2)
time_data = np.arange(NUM_SAMPLES).reshape(NUM_SAMPLES, 1)
target_data = np.array([NORMALISED_TRAINING_DATA[i].flatten() for i in range(NUM_SAMPLES)]).reshape(NUM_SAMPLES, X_RES * Y_RES, 1)

# Instantiate the model
implicit_flow_model_v3 = build_implicit_flow_model_v3(
    branch_input_dim=NUM_COORDS,
    trunk_input_dim=TRUNK_INPUT_DIM,
    time_input_dim=TIME_INPUT_DIM,
    latent_dim=LATENT_DIM,
    train_n=TRAINING_RESOLUTION,
    hidden_units=64,
    num_layers=4
    )
implicit_flow_model_v3.summary()
plot_model(implicit_flow_model_v3, to_file='drive/MyDrive/NIFJet_model_v3_plot.png', show_shapes=True, show_layer_names=True)

TRAINING_FLAG = False

# Set up early stopping to monitor plateau in validation loss
early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)

# Step 1: Initial Training with Adam
implicit_flow_model_v3.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

if TRAINING_FLAG:
  # Initial training with Adam optimizer until early stopping
  history = implicit_flow_model_v3.fit(
      [density_data, coord_data, time_data],
      target_data,
      epochs=1000,  # High epoch count, expecting early stopping to stop training
      batch_size=32,
      validation_split=0.2,
      callbacks=[early_stopping]
  )
  np.save(PATH + 'implicit_flow_v3_history_loss_BEFORE.npy', history.history['loss'])
  np.save(PATH + 'implicit_flow_v3_history_val_loss_BEFORE.npy', history.history['val_loss'])
  plt.figure(figsize=(6,6))
  plt.plot(history.history['loss'], color='blue', label='Loss')
  plt.plot(history.history['val_loss'], color='red', label='Validation Loss')
  plt.legend(loc='upper right', fontsize=15)
  plt.xlabel('Epochs', fontsize=15)
  plt.ylabel('MSE', fontsize=15)
  plt.yscale('log')
  plt.grid()
  plt.xticks(fontsize=15)
  plt.yticks(fontsize=15)
  plt.show()

  # Step 2: Fine-tuning with Nesterov-accelerated SGD (NAG)
  # Compile the model with SGD + Nesterov for continued training
  nag_optimizer = SGD(learning_rate=0.00001, momentum=0.9, nesterov=True)

  # Continue training with NAG
  history_nag = implicit_flow_model_v3.fit(
      [density_data, coord_data, time_data],
      target_data,
      epochs=500,  # Additional epochs for fine-tuning
      batch_size=32,
      validation_split=0.2,
      callbacks=[early_stopping]
  )
  implicit_flow_model_v3.save_weights(PATH + f'IMPLICIT_FLOW_V3_model_weights_AFTER_SGD_res{TRAINING_RESOLUTION}.weights (1).h5')

  plt.figure(figsize=(6,6))
  plt.plot(history.history['loss'], color='blue', label='Loss')
  plt.plot(history.history['val_loss'], color='red', label='Validation Loss')

  plt.axvline(x=len(history.history['loss']), color='black')

  np.save(PATH + 'implicit_flow_v3_history_loss_AFTER.npy', history_nag.history['loss'])
  np.save(PATH + 'implicit_flow_v3_history_val_loss_AFTER.npy', history_nag.history['val_loss'])
  NAG_history = np.zeros(len(history.history['loss']))
  NAG_history[:] = np.nan
  plt.plot(np.append(NAG_history, history_nag.history['loss']), color='blue', linestyle='--')
  plt.plot(np.append(NAG_history, history_nag.history['val_loss']), color='red', linestyle='--')

  plt.legend(loc='upper right', fontsize=15)
  plt.xlabel('Epochs', fontsize=15)
  plt.ylabel('MSE', fontsize=15)
  plt.yscale('log')
  plt.grid()
  plt.xticks(fontsize=15)
  plt.yticks(fontsize=15)
  plt.show()

else:

  #implicit_flow_model_v3.load_weights(f'drive/MyDrive/IMPLICIT_FLOW_V3_model_weights_BEFORE_SGD_res{TRAINING_RESOLUTION}.weights.h5')
  implicit_flow_model_v3.load_weights(PATH + f'IMPLICIT_FLOW_V3_model_weights_AFTER_SGD_res{TRAINING_RESOLUTION}.weights (1).h5')

LOSS_BEFORE = np.load(PATH + 'implicit_flow_v3_history_loss_BEFORE.npy', allow_pickle=True)
VAL_LOSS_BEFORE = np.load(PATH + 'implicit_flow_v3_history_val_loss_BEFORE.npy', allow_pickle=True)
LOSS_AFTER = np.load(PATH + 'implicit_flow_v3_history_loss_AFTER.npy', allow_pickle=True)
VAL_LOSS_AFTER = np.load(PATH + 'implicit_flow_v3_history_val_loss_AFTER.npy', allow_pickle=True)

plt.figure(figsize=(6,6))
plt.plot(LOSS_BEFORE, color='blue', label='Loss')
plt.plot(VAL_LOSS_BEFORE, color='red', label='Validation Loss')

plt.axvline(x=len(LOSS_BEFORE), color='black')

NAG_history = np.zeros(len(LOSS_BEFORE))
NAG_history[:] = np.nan
plt.plot(np.append(NAG_history, LOSS_AFTER), color='blue', linestyle='--', alpha=0.5)
plt.plot(np.append(NAG_history, VAL_LOSS_AFTER), color='red', linestyle='--', alpha=0.5)

plt.legend(loc='upper right', fontsize=15)
plt.xlabel('Epochs', fontsize=15)
plt.ylabel('MSE', fontsize=15)
plt.xscale('log')
plt.yscale('log')
plt.grid()
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.show()









FIGURE_DIM = 6
TEST_RESOLUTION = 128
ALPHA = 0.3
VARIABLE = 'Density'

if not TRAINING_RESOLUTION == TEST_RESOLUTION:
  X_RES, Y_RES = TEST_RESOLUTION, TEST_RESOLUTION
  x_train_mesh = np.linspace(0, 1, X_RES)
  y_train_mesh = np.linspace(0, 1, Y_RES)
  X_train_mesh, Y_train_mesh = np.meshgrid(x_train_mesh, y_train_mesh)  # Shape: (32, 32)
  mesh_points_train = np.stack([X_train_mesh.ravel(), Y_train_mesh.ravel()], axis=-1)  # Shape: (1024, 2)
  # Trunk inputs are the coordinates (x, y) for each point on the 2D mesh
  COORD_DATA = np.tile(mesh_points_train, (NUM_SAMPLES, 1, 1))  # Shape: (100, 1024, 2)

PREDICTIONS = [[] for _ in range(NUM_SAMPLES)]
NORMALISED_ACTUALS = NORMALISED_TRAINING_DATA
PREDICTED_JET_LENGTHS = [[] for _ in range(NUM_SAMPLES)]
ACTUAL_JET_LENGTHS = [[] for _ in range(NUM_SAMPLES)]
SLICE_JET_LENGTHS = [[] for _ in range(NUM_SAMPLES)]

PREDICTED_AVERAGE_DENSITY = np.zeros(NUM_SAMPLES)
ACTUAL_AVERAGE_DENSITY = np.zeros(NUM_SAMPLES)
SLICE_AVERAGE_DENSITY = np.zeros(NUM_SAMPLES)

THRESHOLD_BELOW, THRESHOLD_ABOVE = 0.7, 1
THRESHOLD_BELOW1, THRESHOLD_ABOVE1 = 0, 0.4
INPUT_RESOLUTION = 128
NORMALISED_INPUT_DATA_PATH = f'drive/MyDrive/NORMALISED_INPUT_DATA_res{INPUT_RESOLUTION}.npy'
NORMALISED_INPUT_DATA = np.load(NORMALISED_INPUT_DATA_PATH, allow_pickle=True)
INFERENCE_TIMES = [[] for _ in range(NUM_SAMPLES)]
#NORMALISED_TEST_DATA_PATH = f'drive/MyDrive/NORMALISED_TRAINING_DATA_res{TEST_RESOLUTION}.npy'
#if NORMALISED_TEST_DATA_PATH in glob.glob('drive/MyDrive/*'):
#  NORMALISED_TEST_DATA = np.load(NORMALISED_TEST_DATA_PATH, allow_pickle=True)
#else:
#  NORMALISED_TEST_DATA = [scale_array(NORMALISED_TRAINING_DATA[i], TEST_RESOLUTION / TRAINING_RESOLUTION) for i in range(NORMALISED_TRAINING_DATA.shape[0])]

for SNAPSHOT_NUM in tqdm(range(NUM_SAMPLES)):
  #density_snapshot = NORMALISED_TRAINING_DATA[SNAPSHOT_NUM].reshape(TRAINING_RESOLUTION, TRAINING_RESOLUTION, 1).astype(np.float32)
  time_snapshot = (np.ones(TEST_RESOLUTION) * SNAPSHOT_NUM).astype(np.float32)

  # Perform inference
  start_time = datetime.datetime.now()

  #prediction = implicit_flow_model_v3.predict([
  #                                            density_data[SNAPSHOT_NUM].reshape(1, TRAINING_RESOLUTION, TRAINING_RESOLUTION, 1),
  #                                            COORD_DATA[SNAPSHOT_NUM].reshape(1, X_RES * Y_RES, 2),
  #                                            time_data[SNAPSHOT_NUM].reshape(1, 1)
  #                                            ]
  #)

  if SNAPSHOT_NUM == 0:
    #input_img = NORMALISED_ACTUALS[SNAPSHOT_NUM]
    input_img = NORMALISED_INPUT_DATA[SNAPSHOT_NUM]
    input_img = scale_array(input_img, TRAINING_RESOLUTION / INPUT_RESOLUTION)
    prediction = implicit_flow_model_v3.predict([
                                                input_img.reshape(1, TRAINING_RESOLUTION, TRAINING_RESOLUTION, 1),
                                                COORD_DATA[SNAPSHOT_NUM].reshape(1, X_RES * Y_RES, 2),
                                                time_data[SNAPSHOT_NUM].reshape(1, 1)
                                                ]
    )
  else:
    img = scale_array(img, TRAINING_RESOLUTION / TEST_RESOLUTION)
    prediction = implicit_flow_model_v3.predict([
                                                img.reshape(1, TRAINING_RESOLUTION, TRAINING_RESOLUTION, 1),
                                                COORD_DATA[SNAPSHOT_NUM].reshape(1, X_RES * Y_RES, 2),
                                                time_data[SNAPSHOT_NUM].reshape(1, 1)
                                                ]
    )

  PREDICTION = prediction.reshape(TEST_RESOLUTION, TEST_RESOLUTION)

  ACTUAL = NORMALISED_ACTUALS[SNAPSHOT_NUM]
  SLICE = NORMALISED_INPUT_DATA[SNAPSHOT_NUM]
  #ACTUAL = NORMALISED_ACTUALS[SNAPSHOT_NUM]
  #SLICE = NORMALISED_TEST_DATA[SNAPSHOT_NUM]

  end_time = datetime.datetime.now()
  inference_time = (end_time - start_time).seconds +  (end_time - start_time).microseconds / 1e6
  INFERENCE_TIMES[SNAPSHOT_NUM] = inference_time

  img = PREDICTION
  if ALPHA > 0:
    #zoomed_input = scale_array(NORMALISED_TRAINING_DATA[SNAPSHOT_NUM], TEST_RESOLUTION / TRAINING_RESOLUTION)
    zoomed_input = scale_array(ACTUAL, TEST_RESOLUTION / TRAINING_RESOLUTION)
    img = ALPHA * img + (1 - ALPHA) * zoomed_input

  PREDICTIONS[SNAPSHOT_NUM] = img

  mid = int(TEST_RESOLUTION / 2)
  mid0 = int(ACTUAL.shape[0] / 2)
  #predicted_jet_length = find_peaks(img[:, mid], height=0.6)[0][[0, -1]]
  #predicted_jet_length = find_peaks(np.abs(np.diff(img[:, mid])), height=0.1)[0][[0, -1]]

  predicted_jet_length = find_peaks(np.abs(np.diff(img[:, mid])), height=0.04)[0]
  if predicted_jet_length.size > 0:  # Check if any peaks were found
      predicted_jet_length = predicted_jet_length[[0, -1]]  # Select first and last peaks
  else:
      predicted_jet_length = np.array([0, 0])  # Assign a default value if no peaks found

  smoothed_data = moving_average(ACTUAL[:, mid0], 10)
  peaks = find_peaks(smoothed_data)[0]
  actual_jet_length = [0, 0]
  if len(peaks) > 1:
    actual_jet_length = peaks[[0, -1]]

  sliced_jet_length = find_peaks(SLICE[:, mid])[0][[0, -1]]

  PREDICTED_JET_LENGTHS[SNAPSHOT_NUM] = predicted_jet_length
  ACTUAL_JET_LENGTHS[SNAPSHOT_NUM] = actual_jet_length
  SLICE_JET_LENGTHS[SNAPSHOT_NUM] = sliced_jet_length

  #pl = 500 * (predicted_jet_length[1] - predicted_jet_length[0]) / TEST_RESOLUTION
  #al = 500 * (actual_jet_length[1] - actual_jet_length[0]) / TRAINING_RESOLUTION
  #sl = 500 * (sliced_jet_length[1] - sliced_jet_length[0]) / TEST_RESOLUTION
  #print(pl, al, sl)

  PREDICTED_AVERAGE_DENSITY[SNAPSHOT_NUM] = np.mean(img)
  ACTUAL_AVERAGE_DENSITY[SNAPSHOT_NUM] = np.mean(ACTUAL)
  SLICE_AVERAGE_DENSITY[SNAPSHOT_NUM] = np.mean(SLICE)

  ## create subplots
  #NROWS, NCOLS = 1, 5
  #fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(NCOLS * FIGURE_DIM, FIGURE_DIM))

  #ax[0].imshow(img, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
  #cocoon_ellipse(img, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid, plot_id=0, res=TEST_RESOLUTION, color='black')
  #cocoon_ellipse(img, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid, plot_id=0, res=TEST_RESOLUTION, color='blue')
  #ax[0].set_title(f'Prediction\nInference time: {inference_time:.3f}s', fontsize=15)

  #ax[1].imshow(SLICE, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
  #cocoon_ellipse(SLICE, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid, plot_id=1, res=TEST_RESOLUTION, color='black')
  #cocoon_ellipse(SLICE, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid, plot_id=1, res=TEST_RESOLUTION, color='blue')
  #ax[1].set_title(f'Sliced\n({TEST_RESOLUTION} x {TEST_RESOLUTION})', fontsize=15)

  #ax[2].imshow(img - SLICE, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=-1)
  #ax[2].set_title(r'$\Delta$' + '\n(Prediction, Slice)', fontsize=15)

  #ax[3].imshow(ACTUAL, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
  #cocoon_ellipse(ACTUAL, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid0, plot_id=3, res=TRAINING_RESOLUTION, color='black')
  #cocoon_ellipse(ACTUAL, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid0, plot_id=3, res=TRAINING_RESOLUTION, color='blue')
  #ax[3].set_title(f'Original\n({TRAINING_RESOLUTION} x {TRAINING_RESOLUTION})', fontsize=15)

  #ax[4].plot(np.linspace(-250, 250, TEST_RESOLUTION), img[:, mid], color='blue', label='Prediction')
  #ax[4].plot(np.linspace(-250, 250, TEST_RESOLUTION), zoomed_input[:, mid], color='red', label='Sliced')
  #ax[4].plot(np.linspace(-250, 250, ACTUAL.shape[0]), ACTUAL[:, mid0], color='black', label='Original')
  #ax[4].set_xlabel('x (kpc)', fontsize=15)
  #ax[4].set_ylabel('Density (Normalised)', fontsize=15)
  #ax[4].tick_params(axis="x", labelsize=15)
  #ax[4].tick_params(axis="y", labelsize=15)
  #ax[4].legend(loc='upper right', fontsize=15)
  #ax[4].set_ylim([0, 1])
  #ax[4].grid()
  #ax[4].set_title('Density Distribution\nJet Pole', fontsize=15)

  #for i in range(NCOLS-1):
  #  ax[i].set_aspect('equal')
  #  ax[i].set_xlabel('x (kpc)', fontsize=15)
  #  ax[i].set_ylabel('z (kpc)', fontsize=15)
  #  ax[i].tick_params(axis="x", labelsize=15, rotation=90) # Call tick_params on the respective Axes object
  #  ax[i].tick_params(axis="y", labelsize=15)
  #  cb = plt.colorbar(ax[i].images[0], ax=ax[i], fraction=0.0458, pad=0.04)
  #  cb.set_label(label=f'log(' + r'$\rho$' + ')' + ' (Normalised)', size=15)
  #  cb.ax.tick_params(labelsize=15)

  #fig.suptitle(f'Snapshot: {SNAPSHOT_NUM+1}\n', fontsize=15)
  #plt.tight_layout()

  #plt.show()

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))

ax[0].plot([500 * (j[1] - j[0]) / TEST_RESOLUTION for j in PREDICTED_JET_LENGTHS[:-1]], color='blue', label='Prediction')
ax[0].plot([500 * (j[1] - j[0]) / TEST_RESOLUTION for j in SLICE_JET_LENGTHS[:-1]], color='red', label=f'Sliced ({TEST_RESOLUTION} x {TEST_RESOLUTION})')
ax[0].plot([500 * (j[1] - j[0]) / TRAINING_RESOLUTION for j in ACTUAL_JET_LENGTHS[:-1]], color='black', label='Original')
ax[0].set_xlabel('Snapshot', fontsize=15)
ax[0].set_ylabel('Jet Length (kpc)', fontsize=15)
ax[0].grid()

ax[1].plot(PREDICTED_AVERAGE_DENSITY[:-1], color='blue', label='Prediction')
ax[1].plot(SLICE_AVERAGE_DENSITY[:-1], color='red', label=f'Sliced ({TEST_RESOLUTION} x {TEST_RESOLUTION})')
ax[1].plot(ACTUAL_AVERAGE_DENSITY[:-1], color='black', label=f'Original ({TRAINING_RESOLUTION} x {TRAINING_RESOLUTION})')
ax[1].set_xlabel('Snapshot', fontsize=15)
ax[1].set_ylabel('Average Density (Normalised)', fontsize=15)
#ax[1].set_ylim([0.425, 0.475])
#ax[1].set_yscale('log')
ax[1].grid()
ax[1].legend(loc='upper right', fontsize=15)

for i in range(2):
  ax[i].tick_params(axis="x", labelsize=15)
  ax[i].tick_params(axis="y", labelsize=15)

plt.suptitle(f'Evolution of Jet Length and Average Density\nResolution: ({X_RES} x {Y_RES})', fontsize=15)
plt.tight_layout()
plt.show()



PREDICTED_JET_LENGTH_ERROR = np.divide(
    np.array([500 * (j[1] - j[0]) / TEST_RESOLUTION for j in PREDICTED_JET_LENGTHS[:-1]]) - np.array([500 * (j[1] - j[0]) / TRAINING_RESOLUTION for j in ACTUAL_JET_LENGTHS[:-1]]),
    np.array([500 * (j[1] - j[0]) / TRAINING_RESOLUTION for j in ACTUAL_JET_LENGTHS[:-1]])
          )[5:].mean() * 100

SLICED_JET_LENGTH_ERROR = np.divide(
    np.array([500 * (j[1] - j[0]) / TEST_RESOLUTION for j in SLICE_JET_LENGTHS[:-1]]) - np.array([500 * (j[1] - j[0]) / TRAINING_RESOLUTION for j in ACTUAL_JET_LENGTHS[:-1]]),
    np.array([500 * (j[1] - j[0]) / TRAINING_RESOLUTION for j in ACTUAL_JET_LENGTHS[:-1]])
          )[5:].mean() * 100

print(100 + PREDICTED_JET_LENGTH_ERROR)
print(100 + SLICED_JET_LENGTH_ERROR)

PREDICTED_AVERAGE_DENSITY_ERROR = np.divide(
    PREDICTED_AVERAGE_DENSITY[:-1] - ACTUAL_AVERAGE_DENSITY[:-1],
    ACTUAL_AVERAGE_DENSITY[:-1]
).mean() * 100

SLICED_AVERAGE_DENSITY_ERROR = np.divide(
    SLICE_AVERAGE_DENSITY[:-1] - ACTUAL_AVERAGE_DENSITY[:-1],
    ACTUAL_AVERAGE_DENSITY[:-1]
).mean() * 100

print(100 + PREDICTED_AVERAGE_DENSITY_ERROR)
print(100 + SLICED_AVERAGE_DENSITY_ERROR)















for SNAPSHOT_NUM in tqdm(range(NUM_SAMPLES)):

  # create subplots
    NROWS, NCOLS = 1, 5
    fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(NCOLS * FIGURE_DIM, FIGURE_DIM))

    img = PREDICTIONS[SNAPSHOT_NUM]
    ACTUAL = NORMALISED_ACTUALS[SNAPSHOT_NUM]
    SLICE = NORMALISED_INPUT_DATA[SNAPSHOT_NUM]
    zoomed_input = scale_array(ACTUAL, TEST_RESOLUTION / TRAINING_RESOLUTION)
    inference_time = INFERENCE_TIMES[SNAPSHOT_NUM]

    ax[0].imshow(img, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
    #cocoon_ellipse(img, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid, plot_id=0, res=TEST_RESOLUTION, color='black')
    #cocoon_ellipse(img, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid, plot_id=0, res=TEST_RESOLUTION, color='blue')
    ax[0].set_title(f'Prediction\nInference time: {inference_time:.3f}s', fontsize=15)

    ax[1].imshow(SLICE, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
    #cocoon_ellipse(SLICE, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid, plot_id=1, res=TEST_RESOLUTION, color='black')
    #cocoon_ellipse(SLICE, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid, plot_id=1, res=TEST_RESOLUTION, color='blue')
    ax[1].set_title(f'Sliced\n({TEST_RESOLUTION} x {TEST_RESOLUTION})', fontsize=15)

    ax[2].imshow(img - zoomed_input, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=-1)
    ax[2].set_title(r'$\Delta$' + '\n(Prediction, Original)', fontsize=15)

    ax[3].imshow(ACTUAL, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
    #cocoon_ellipse(ACTUAL, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid0, plot_id=3, res=TRAINING_RESOLUTION, color='black')
    #cocoon_ellipse(ACTUAL, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid0, plot_id=3, res=TRAINING_RESOLUTION, color='blue')
    ax[3].set_title(f'Original\n({TRAINING_RESOLUTION} x {TRAINING_RESOLUTION})', fontsize=15)

    ax[4].plot(np.linspace(-250, 250, TEST_RESOLUTION), img[:, mid], color='blue', label='Prediction')
    ax[4].plot(np.linspace(-250, 250, TEST_RESOLUTION), zoomed_input[:, mid], color='red', label='Sliced')
    ax[4].plot(np.linspace(-250, 250, ACTUAL.shape[0]), ACTUAL[:, mid0], color='black', label='Original')
    ax[4].set_xlabel('x (kpc)', fontsize=15)
    ax[4].set_ylabel('Density (Normalised)', fontsize=15)
    ax[4].tick_params(axis="x", labelsize=15)
    ax[4].tick_params(axis="y", labelsize=15)
    ax[4].legend(loc='upper right', fontsize=15)
    ax[4].set_ylim([0, 1])
    ax[4].grid()
    ax[4].set_title('Density Distribution\nJet Pole', fontsize=15)

    for i in range(NCOLS-1):
      ax[i].set_aspect('equal')
      ax[i].set_xlabel('x (kpc)', fontsize=15)
      ax[i].set_ylabel('z (kpc)', fontsize=15)
      ax[i].tick_params(axis="x", labelsize=15, rotation=90) # Call tick_params on the respective Axes object
      ax[i].tick_params(axis="y", labelsize=15)
      cb = plt.colorbar(ax[i].images[0], ax=ax[i], fraction=0.0458, pad=0.04)
      cb.set_label(label=f'log(' + r'$\rho$' + ')' + ' (Normalised)', size=15)
      cb.ax.tick_params(labelsize=15)

    fig.suptitle(f'Snapshot: {SNAPSHOT_NUM+1}\n', fontsize=15)
    plt.tight_layout()

    plt.show()

# Example usage
# Create a list of figures with 5 subplots as an example
figures = []

for SNAPSHOT_NUM in tqdm(range(NUM_SAMPLES)):

    # create subplots
    NROWS, NCOLS = 1, 3
    fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(NCOLS * FIGURE_DIM, FIGURE_DIM))

    img = PREDICTIONS[SNAPSHOT_NUM]
    ACTUAL = NORMALISED_ACTUALS[SNAPSHOT_NUM]
    SLICE = NORMALISED_INPUT_DATA[SNAPSHOT_NUM]
    zoomed_input = scale_array(ACTUAL, TEST_RESOLUTION / TRAINING_RESOLUTION)
    inference_time = INFERENCE_TIMES[SNAPSHOT_NUM]

    ax[0].imshow(img, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
    #cocoon_ellipse(img, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid, plot_id=0, res=TEST_RESOLUTION, color='black')
    #cocoon_ellipse(img, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid, plot_id=0, res=TEST_RESOLUTION, color='blue')
    ax[0].set_title(f'Prediction\nInference time: {inference_time:.3f}s', fontsize=15)

    #ax[1].imshow(SLICE, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
    ##cocoon_ellipse(SLICE, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid, plot_id=1, res=TEST_RESOLUTION, color='black')
    ##cocoon_ellipse(SLICE, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid, plot_id=1, res=TEST_RESOLUTION, color='blue')
    #ax[1].set_title(f'Sliced\n({TEST_RESOLUTION} x {TEST_RESOLUTION})', fontsize=15)

    #ax[2].imshow(img - SLICE, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=-1)
    #ax[2].set_title(r'$\Delta$' + '\n(Prediction, Slice)', fontsize=15)

    ax[1].imshow(ACTUAL, origin='lower', cmap='jet', extent=[-250, 250, -250, 250], vmax=1, vmin=0)
    #cocoon_ellipse(ACTUAL, threshold_below=THRESHOLD_BELOW, threshold_above=THRESHOLD_ABOVE, mid=mid0, plot_id=3, res=TRAINING_RESOLUTION, color='black')
    #cocoon_ellipse(ACTUAL, threshold_below=THRESHOLD_BELOW1, threshold_above=THRESHOLD_ABOVE1, mid=mid0, plot_id=3, res=TRAINING_RESOLUTION, color='blue')
    ax[1].set_title(f'Original\n({TRAINING_RESOLUTION} x {TRAINING_RESOLUTION})', fontsize=15)

    ax[2].plot(np.linspace(-250, 250, TEST_RESOLUTION), img[:, mid], color='blue', label='Prediction')
    ax[2].plot(np.linspace(-250, 250, TEST_RESOLUTION), zoomed_input[:, mid], color='red', label='Sliced')
    ax[2].plot(np.linspace(-250, 250, ACTUAL.shape[0]), ACTUAL[:, mid0], color='black', label='Original')
    ax[2].set_xlabel('x (kpc)', fontsize=15)
    ax[2].set_ylabel('Density (Normalised)', fontsize=15)
    ax[2].tick_params(axis="x", labelsize=15)
    ax[2].tick_params(axis="y", labelsize=15)
    ax[2].legend(loc='upper right', fontsize=15)
    ax[2].set_ylim([0, 1])
    ax[2].grid()
    ax[2].set_title('Density Distribution\nJet Pole', fontsize=15)

    for i in range(NCOLS-1):
      ax[i].set_aspect('equal')
      ax[i].set_xlabel('x (kpc)', fontsize=15)
      ax[i].set_ylabel('z (kpc)', fontsize=15)
      ax[i].tick_params(axis="x", labelsize=15, rotation=90) # Call tick_params on the respective Axes object
      ax[i].tick_params(axis="y", labelsize=15)
      cb = plt.colorbar(ax[i].images[0], ax=ax[i], fraction=0.0458, pad=0.04)
      cb.set_label(label=f'log(' + r'$\rho$' + ')' + ' (Normalised)', size=15)
      cb.ax.tick_params(labelsize=15)

    fig.suptitle(f'Snapshot: {SNAPSHOT_NUM+1}\n', fontsize=15)
    plt.tight_layout()

    # Add to the list of figures
    figures.append(fig)

# Convert figures to GIF
save_subplots_as_gif(figures, output_filename='drive/MyDrive/BASE_II_animation_no_cocoon.gif', fps=5)

# Close all figures to free memory
for fig in figures:
    plt.close(fig)

