# BanditNAS4SciML
Bandit Neural Architecture Search for Scientific Machine Learning

_Neural Architecture Search_ (NAS) referring to optimising the design and training of deep learning algorithms, requires critical set-up choices to yield small validation loss. While this task has recently been posed as a pure-exploration bandit problem, we show that this fails for applications in scientific machine learning. We propose the non-stochastic multi-armed bandit that balances exploitation and exploration as a more appropriate setting for this problem and introduce a novel algorithm, _BanditNAS_ to meet the challenge. We analyse its theoretical properties and compare BanditNAS with state-of-the-art approaches for optimising deep learning models. Empirical experiments show that our framework outperforms other non-stochastic bandits by 10% when validation losses are noisy, 50% when losses are slow to converge and 95% when fine-tuning is performed using multiple optimisation procedures.
